{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv-Ox8VXd-M5"
      },
      "source": [
        "# Project Milestone Two: Modeling and Feature Engineering\n",
        "\n",
        "### Due: Midnight on August 3 (with 2-hour grace period) and worth 50 points\n",
        "\n",
        "### Overview\n",
        "\n",
        "This milestone builds on your work from Milestone 1 and will complete the coding portion of your project. You will:\n",
        "\n",
        "1. Pick 3 modeling algorithms from those we have studied.\n",
        "2. Evaluate baseline models using default settings.\n",
        "3. Engineer new features and re-evaluate models.\n",
        "4. Use feature selection techniques and re-evaluate.\n",
        "5. Fine-tune for optimal performance.\n",
        "6. Select your best model and report on your results.\n",
        "\n",
        "You must do all work in this notebook and upload to your team leader's account in Gradescope. There is no\n",
        "Individual Assessment for this Milestone.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z_wpj5D-Bula"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E8EXuZdvd-M7"
      },
      "outputs": [],
      "source": [
        "# ===================================\n",
        "# Useful Imports: Add more as needed\n",
        "# ===================================\n",
        "\n",
        "# Standard Libraries\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import io\n",
        "import zipfile\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "from itertools import chain, combinations\n",
        "\n",
        "\n",
        "# Data Science Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.ticker as mticker  # Optional: Format y-axis labels as dollars\n",
        "import seaborn as sns\n",
        "\n",
        "# Scikit-learn (Machine Learning)\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    cross_val_score,\n",
        "    GridSearchCV,\n",
        "    RandomizedSearchCV,\n",
        "    RepeatedKFold\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_selection import SequentialFeatureSelector, f_regression, SelectKBest\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Progress Tracking\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =============================\n",
        "# Global Variables\n",
        "# =============================\n",
        "random_state = 42\n",
        "\n",
        "# =============================\n",
        "# Utility Functions\n",
        "# =============================\n",
        "\n",
        "# Format y-axis labels as dollars with commas (optional)\n",
        "def dollar_format(x, pos):\n",
        "    return f'${x:,.0f}'\n",
        "\n",
        "# Convert seconds to HH:MM:SS format\n",
        "def format_hms(seconds):\n",
        "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UXwIMB6d-M8"
      },
      "source": [
        "### Prelude: Load your Preprocessed Dataset from Milestone 1\n",
        "\n",
        "In Milestone 1, you handled missing values, encoded categorical features, and explored your data. Before you begin this milestone, you’ll need to load that cleaned dataset and prepare it for modeling. We do **not yet** want the dataset you developed in the last part of Milestone 1, with\n",
        "feature engineering---that will come a bit later!\n",
        "\n",
        "Here’s what to do:\n",
        "\n",
        "1. Return to your Milestone 1 notebook and rerun your code through Part 3, where your dataset was fully cleaned (assume it’s called `df_cleaned`).\n",
        "\n",
        "2. **Save** the cleaned dataset to a file by running:\n",
        "\n",
        ">   df_cleaned.to_csv(\"zillow_cleaned.csv\", index=False)\n",
        "\n",
        "3. Switch to this notebook and **load** the saved data:\n",
        "\n",
        ">   df = pd.read_csv(\"zillow_cleaned.csv\")\n",
        "\n",
        "4. Create a **train/test split** using `train_test_split`.  \n",
        "   \n",
        "6. **Standardize** the features (but not the target!) using **only the training data.** This ensures consistency across models without introducing data leakage from the test set:\n",
        "\n",
        ">   scaler = StandardScaler()   \n",
        ">   X_train_scaled = scaler.fit_transform(X_train)    \n",
        "  \n",
        "**Notes:**\n",
        "\n",
        "- You will have to redo the scaling step if you introduce new features (which have to be scaled as well).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-RidUzJpHnn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**LOAD CLEANED MILESTONE 1 ZILLOW DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SWMs_p1EkShK"
      },
      "outputs": [],
      "source": [
        "#url = \"https://www.cs.bu.edu/fac/snyder/cs505/Data/zillow_dataset.csv\"\n",
        "\n",
        "#filename = os.path.basename(urlparse(url).path)\n",
        "\n",
        "#if not os.path.exists(filename):\n",
        "#    try:\n",
        "#        print(\"Downloading the file...\")\n",
        "#        response = requests.get(url)\n",
        "#        response.raise_for_status()  # Raise an error for bad status codes\n",
        "#        with open(filename, \"wb\") as f:\n",
        "#            f.write(response.content)\n",
        "#        print(\"File downloaded successfully.\")\n",
        "#    except requests.exceptions.RequestException as e:\n",
        "#        print(f\"Error downloading the file: {e}\")\n",
        "#else:\n",
        "#    print(\"File already exists. Skipping download.\")\n",
        "\n",
        "#df = pd.read_csv(filename)\n",
        "\n",
        "# df = pd.read_csv(\"zillow_cleaned.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkTg1jwK6qvZ",
        "outputId": "c4b7b977-9cfb-4628-d459-83ec55bca7e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists. Skipping download.\n"
          ]
        }
      ],
      "source": [
        "url = \"https://raw.githubusercontent.com/jydeleon/JazminRepo-603/refs/heads/main/zillow_cleaned.csv\"\n",
        "filename = \"zillow_cleaned.csv\"\n",
        "\n",
        "# Download the file only if it doesn't exist locally\n",
        "if not os.path.exists(filename):\n",
        "    try:\n",
        "        print(\"Downloading the file...\")\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise error for bad status\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        print(\"File downloaded successfully.\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading the file: {e}\")\n",
        "else:\n",
        "    print(\"File already exists. Skipping download.\")\n",
        "\n",
        "df = pd.read_csv(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDfbLpe2p1JU",
        "outputId": "2583d526-252f-4e04-eb8c-762bc2a81797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 77578 entries, 0 to 77577\n",
            "Data columns (total 32 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   airconditioningtypeid         77578 non-null  float64\n",
            " 1   basementsqft                  77578 non-null  float64\n",
            " 2   bathroomcnt                   77578 non-null  float64\n",
            " 3   bedroomcnt                    77578 non-null  float64\n",
            " 4   buildingqualitytypeid         77578 non-null  float64\n",
            " 5   calculatedbathnbr             77578 non-null  float64\n",
            " 6   calculatedfinishedsquarefeet  77578 non-null  float64\n",
            " 7   finishedsquarefeet12          77578 non-null  float64\n",
            " 8   fips                          77578 non-null  float64\n",
            " 9   fullbathcnt                   77578 non-null  float64\n",
            " 10  garagecarcnt                  77578 non-null  float64\n",
            " 11  garagetotalsqft               77578 non-null  float64\n",
            " 12  heatingorsystemtypeid         77578 non-null  float64\n",
            " 13  latitude                      77578 non-null  float64\n",
            " 14  longitude                     77578 non-null  float64\n",
            " 15  lotsizesquarefeet             77578 non-null  float64\n",
            " 16  poolcnt                       77578 non-null  float64\n",
            " 17  poolsizesum                   77578 non-null  float64\n",
            " 18  propertycountylandusecode     77578 non-null  object \n",
            " 19  propertylandusetypeid         77578 non-null  float64\n",
            " 20  propertyzoningdesc            77578 non-null  object \n",
            " 21  rawcensustractandblock        77578 non-null  float64\n",
            " 22  regionidcity                  77578 non-null  float64\n",
            " 23  regionidzip                   77578 non-null  float64\n",
            " 24  roomcnt                       77578 non-null  float64\n",
            " 25  threequarterbathnbr           77578 non-null  float64\n",
            " 26  unitcnt                       77578 non-null  float64\n",
            " 27  yearbuilt                     77578 non-null  float64\n",
            " 28  numberofstories               77578 non-null  float64\n",
            " 29  assessmentyear                77578 non-null  float64\n",
            " 30  censustractandblock           77578 non-null  float64\n",
            " 31  taxvaluedollarcnt             77578 non-null  float64\n",
            "dtypes: float64(30), object(2)\n",
            "memory usage: 18.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zBmR9MXpMxo"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**TRAIN/TEST SPLIT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "Tb0gnPZKsVjy",
        "outputId": "bf7524a7-ecea-490d-fd4d-0d04c639275f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "propertycountylandusecode      75\n",
              "propertyzoningdesc           1907\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>propertycountylandusecode</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>propertyzoningdesc</th>\n",
              "      <td>1907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df.select_dtypes(exclude='number').nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8HnRzZQPsdd8"
      },
      "outputs": [],
      "source": [
        "# Drop the high-cardinality column\n",
        "df = df.drop(columns=[\"propertyzoningdesc\"])\n",
        "\n",
        "# Encode the moderate-cardinality column\n",
        "encoder = OrdinalEncoder()\n",
        "df[[\"propertycountylandusecode\"]] = encoder.fit_transform(df[[\"propertycountylandusecode\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "jg5moRSqs1ms",
        "outputId": "d5fa3ebe-d8b1-4e73-c4d5-6174b89ca495"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], dtype: float64)"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df.select_dtypes(exclude='number').nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t5zq3wj3-nlw",
        "outputId": "6083915a-d385-4073-a233-071d949c9793"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            Name     Type  Missing %  Unique Values\n",
              "0          airconditioningtypeid  float64        0.0              6\n",
              "1                   basementsqft  float64        0.0             44\n",
              "2                    bathroomcnt  float64        0.0             22\n",
              "3                     bedroomcnt  float64        0.0             16\n",
              "4          buildingqualitytypeid  float64        0.0             13\n",
              "5              calculatedbathnbr  float64        0.0             22\n",
              "6   calculatedfinishedsquarefeet  float64        0.0           4973\n",
              "7           finishedsquarefeet12  float64        0.0           4869\n",
              "8                           fips  float64        0.0              3\n",
              "9                    fullbathcnt  float64        0.0             14\n",
              "10                  garagecarcnt  float64        0.0             15\n",
              "11               garagetotalsqft  float64        0.0            840\n",
              "12         heatingorsystemtypeid  float64        0.0             11\n",
              "13                      latitude  float64        0.0          64037\n",
              "14                     longitude  float64        0.0          62460\n",
              "15             lotsizesquarefeet  float64        0.0          18849\n",
              "16                       poolcnt  float64        0.0              1\n",
              "17                   poolsizesum  float64        0.0            263\n",
              "18     propertycountylandusecode  float64        0.0             75\n",
              "19         propertylandusetypeid  float64        0.0             13\n",
              "20        rawcensustractandblock  float64        0.0          39188\n",
              "21                  regionidcity  float64        0.0            176\n",
              "22                   regionidzip  float64        0.0            390\n",
              "23                       roomcnt  float64        0.0             16\n",
              "24           threequarterbathnbr  float64        0.0              5\n",
              "25                       unitcnt  float64        0.0              9\n",
              "26                     yearbuilt  float64        0.0            137\n",
              "27               numberofstories  float64        0.0              5\n",
              "28                assessmentyear  float64        0.0              1\n",
              "29           censustractandblock  float64        0.0          39007\n",
              "30             taxvaluedollarcnt  float64        0.0          50949"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e38b6e67-14a9-4888-9253-9a849d673ffd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Type</th>\n",
              "      <th>Missing %</th>\n",
              "      <th>Unique Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>airconditioningtypeid</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>basementsqft</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bathroomcnt</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bedroomcnt</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>buildingqualitytypeid</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>calculatedbathnbr</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>calculatedfinishedsquarefeet</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>finishedsquarefeet12</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fips</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>fullbathcnt</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>garagecarcnt</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>garagetotalsqft</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>heatingorsystemtypeid</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>latitude</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>longitude</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>lotsizesquarefeet</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>poolcnt</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>poolsizesum</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>propertycountylandusecode</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>propertylandusetypeid</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>rawcensustractandblock</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>regionidcity</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>regionidzip</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>roomcnt</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>threequarterbathnbr</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>unitcnt</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>yearbuilt</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>numberofstories</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>assessmentyear</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>censustractandblock</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>taxvaluedollarcnt</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50949</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e38b6e67-14a9-4888-9253-9a849d673ffd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e38b6e67-14a9-4888-9253-9a849d673ffd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e38b6e67-14a9-4888-9253-9a849d673ffd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e3b5f183-9164-419b-8d82-fe04f35dd08c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3b5f183-9164-419b-8d82-fe04f35dd08c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e3b5f183-9164-419b-8d82-fe04f35dd08c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7280d477-5085-4b46-903e-d416f0e4f1f2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7280d477-5085-4b46-903e-d416f0e4f1f2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_summary",
              "summary": "{\n  \"name\": \"df_summary\",\n  \"rows\": 31,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"numberofstories\",\n          \"lotsizesquarefeet\",\n          \"roomcnt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"float64\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Missing %\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unique Values\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19504,\n        \"min\": 1,\n        \"max\": 64037,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Generate a summary of data types, missing %, and unique values\n",
        "df_summary = pd.DataFrame({\n",
        "    'Name': df.columns,\n",
        "    'Type': df.dtypes.values,\n",
        "    'Missing %': df.isnull().mean().values * 100,\n",
        "    'Unique Values': df.nunique().values\n",
        "})\n",
        "\n",
        "# Display top rows of the summary\n",
        "df_summary = df_summary.sort_values(by='Missing %', ascending=False)\n",
        "df_summary.reset_index(drop=True, inplace=True)\n",
        "df_summary  # or just print(df_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QxM6gY9PiI77"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=[\"taxvaluedollarcnt\"])\n",
        "y = df[\"taxvaluedollarcnt\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDAshrefpP3K"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**STANDARDIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yKXgpjVdn9qN"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform the training data\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU5TIXYfd-M9"
      },
      "source": [
        "### Part 1: Picking Three Models and Establishing Baselines [6 pts]\n",
        "\n",
        "Apply the following regression models to the scaled training dataset using **default parameters** for **three** of the models we have worked with this term:\n",
        "\n",
        "- Linear Regression\n",
        "- Ridge Regression\n",
        "- Lasso Regression\n",
        "- Decision Tree Regression\n",
        "- Bagging\n",
        "- Random Forest\n",
        "- Gradient Boosting Trees\n",
        "\n",
        "For each of the three models:\n",
        "- Use **repeated cross-validation** (e.g., 5 folds, 5 repeats).\n",
        "- Report the **mean and standard deviation of CV MAE Score**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "evhnutWzBEWO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKDUQNoWE76N"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**MODEL 1: LINEAR REGRESSION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S611A9ymBAlj",
        "outputId": "1db8ed72-1539-414d-e28b-eb55229339f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MAE: 243233.1549665191\n",
            "Std MAE: 4286.326318704401\n"
          ]
        }
      ],
      "source": [
        "#Repeated cross-validation\n",
        "repeated_cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
        "\n",
        "#Linear Regression Model\n",
        "lr_model = LinearRegression()\n",
        "\n",
        "# Evaluate using cross_val_score with scoring='neg_mean_absolute_error'\n",
        "lr_mae_scores = cross_val_score(lr_model, X_train_scaled, y_train,\n",
        "                             scoring='neg_mean_absolute_error',\n",
        "                             cv=repeated_cv)\n",
        "\n",
        "# Convert to positive MAE\n",
        "lr_mae_scores = -lr_mae_scores\n",
        "print(\"Mean MAE:\", np.mean(lr_mae_scores))\n",
        "print(\"Std MAE:\", np.std(lr_mae_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsfCQh_QFDWp"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**MODEL 2: RANDOM FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UqDo_gOBxSU"
      },
      "outputs": [],
      "source": [
        "# Set up repeated cross-validation\n",
        "repeated_cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
        "\n",
        "# Random Forest with default parameters\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Evaluate using negative MAE\n",
        "rf_mae_scores = cross_val_score(rf_model, X_train_scaled, y_train,\n",
        "                                scoring='neg_mean_absolute_error',\n",
        "                                cv=repeated_cv)\n",
        "\n",
        "# Convert scores to positive MAE\n",
        "rf_mae_scores = -rf_mae_scores\n",
        "print(\"Random Forest - Mean MAE:\", np.mean(rf_mae_scores))\n",
        "print(\"Random Forest - Std MAE:\", np.std(rf_mae_scores))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2pfN98YFKc4"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**MODEL 3: GRADIENT BOOSTING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxWcL084C_hW"
      },
      "outputs": [],
      "source": [
        "# Set up repeated CV\n",
        "repeated_cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
        "\n",
        "# Gradient Boosting model\n",
        "gb_model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Evaluate with negative MAE\n",
        "gb_mae_scores = cross_val_score(gb_model, X_train_scaled, y_train,\n",
        "                             scoring='neg_mean_absolute_error',\n",
        "                             cv=repeated_cv)\n",
        "\n",
        "# Convert to positive and summarize\n",
        "gb_mae_scores = -gb_mae_scores\n",
        "print(\"Gradient Boosting - Mean MAE:\", np.mean(gb_mae_scores))\n",
        "print(\"Gradient Boosting - Std MAE:\", np.std(gb_mae_scores))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgl_nJlyd-M-"
      },
      "source": [
        "### Part 1: Discussion [3 pts]\n",
        "\n",
        "In a paragraph or well-organized set of bullet points, briefly compare and discuss:\n",
        "\n",
        "  - Which model performed best overall?\n",
        "  - Which was most stable (lowest std)?\n",
        "  - Any signs of overfitting or underfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pANM2gvVd-M-"
      },
      "source": [
        "**Best Performing Model:**\n",
        "The Random Forest model achieved the lowest mean MAE of 190180.5471, indicating it had the best predictive accuracy among the three models tested.\n",
        "\n",
        "**Most Stable Model:**\n",
        "The Random Forest model also had the lowest standard deviation of MAE at 2190.6051, making it the most consistent across cross-validation folds and repeats.\n",
        "\n",
        "**Overfitting or Underfitting Signs:**\n",
        "\n",
        "Linear Regression had the highest MAE (243233.155) and a moderate standard deviation (4286.3263), suggesting it may be underfitting, as it likely fails to capture complex nonlinear patterns in the data.\n",
        "\n",
        "Gradient Boosting performed slightly worse than Random Forest (MAE 198676.5034) with a higher standard deviation (2799.2804), which could indicate mild overfitting due to its iterative nature and sensitivity to noise.\n",
        "\n",
        "Random Forest shows a strong balance between accuracy and stability, with no major signs of overfitting in this baseline setting.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1M5qqxRd-M-"
      },
      "source": [
        "### Part 2: Feature Engineering [6 pts]\n",
        "\n",
        "Pick **at least three new features** based on your Milestone 1, Part 5, results. You may pick new ones or\n",
        "use the same ones you chose for Milestone 1.\n",
        "\n",
        "Add these features to `X_train` (use your code and/or files from Milestone 1) and then:\n",
        "- Scale using `StandardScaler`\n",
        "- Re-run the 3 models listed above (using default settings and repeated cross-validation again).\n",
        "- Report the **mean and standard deviation of CV MAE Scores**.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LSjFU5BVLxN"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Step 1: Add Engineered Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn1Q7tT5d-M_"
      },
      "outputs": [],
      "source": [
        "# Copy from the original df\n",
        "df_fe = df.copy()\n",
        "\n",
        "# Log-transform target and square footage\n",
        "df_fe['log_taxvaluedollarcnt'] = np.log1p(df_fe['taxvaluedollarcnt'])\n",
        "df_fe['log_calculatedfinishedsquarefeet'] = np.log1p(df_fe['calculatedfinishedsquarefeet'])\n",
        "\n",
        "# Add ratio feature\n",
        "df_fe['value_per_sqft'] = df_fe['taxvaluedollarcnt'] / (df_fe['calculatedfinishedsquarefeet'] + 1e-3)\n",
        "\n",
        "# Drop rows with missing values in the new features\n",
        "df_fe.dropna(subset=['value_per_sqft', 'log_taxvaluedollarcnt', 'log_calculatedfinishedsquarefeet'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKdtiLbpV3mJ"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        " **Step 2: Train-Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6CeSzioU3VX"
      },
      "outputs": [],
      "source": [
        "X = df_fe.drop(columns=[\"taxvaluedollarcnt\"])  # drop raw target\n",
        "y = df_fe[\"taxvaluedollarcnt\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdTUpGfhWAPM"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Step 3: Standardize Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ykxfos6U7eX"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQYahIPiWOJ0"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Step 4: Run the 3 Models with Repeated CV**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOCrj1ltjM6F"
      },
      "outputs": [],
      "source": [
        "repeated_cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(model, name):\n",
        "    scores = cross_val_score(model, X_train_scaled, y_train,\n",
        "                             scoring='neg_mean_absolute_error',\n",
        "                             cv=repeated_cv)\n",
        "    scores = -scores\n",
        "    print(f\"{name} - Mean MAE: {np.mean(scores):.2f}\")\n",
        "    print(f\"{name} - Std MAE: {np.std(scores):.2f}\")\n",
        "    print()\n",
        "\n",
        "# Run models\n",
        "evaluate_model(LinearRegression(), \"Linear Regression\")\n",
        "evaluate_model(RandomForestRegressor(random_state=42), \"Random Forest\")\n",
        "evaluate_model(GradientBoostingRegressor(random_state=42), \"Gradient Boosting\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXhygsXBd-M_"
      },
      "source": [
        "### Part 2: Discussion [3 pts]\n",
        "\n",
        "Reflect on the impact of your new features:\n",
        "\n",
        "- Did any models show notable improvement in performance?\n",
        "\n",
        "- Which new features seemed to help — and in which models?\n",
        "\n",
        "- Do you have any hypotheses about why a particular feature helped (or didn’t)?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pltbRWNd-M_"
      },
      "source": [
        "**Improvement in Model Performance:**\n",
        "After adding the engineered features (log_taxvaluedollarcnt, log_calculatedfinishedsquarefeet, and value_per_sqft), all three models showed modest improvements. The most noticeable gains were seen in the Linear Regression model, which had previously struggled. This suggests that the new features helped simplify complex relationships in the data.\n",
        "\n",
        "**Helpful Features:**\n",
        "The log-transformed features (log_taxvaluedollarcnt and log_calculatedfinishedsquarefeet) were especially helpful, likely because they reduced skewness and stabilized variance. This made it easier for the Linear Regression model to perform well.\n",
        "The value_per_sqft feature was likely helpful for both tree-based models, since it combined size and value into one metric that aligned well with how prices vary across properties.\n",
        "\n",
        "**Hypotheses:**\n",
        "Linear Regression benefits when relationships between variables are more linear and when distributions are more normal. The log transformations helped in this area, leading to lower error.\n",
        "Tree-based models like Random Forest and Gradient Boosting already handle nonlinearities well, so the improvements were smaller. However, adding a domain-informed ratio like value_per_sqft still provided meaningful context for those models to work with.> Your text here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCFLwpuZd-M_"
      },
      "source": [
        "### Part 3: Feature Selection [6 pts]\n",
        "\n",
        "Using the full set of features (original + engineered):\n",
        "- Apply **feature selection** methods to investigate whether you can improve performance.\n",
        "  - You may use forward selection, backward selection, or feature importance from tree-based models.\n",
        "- For each model, identify the **best-performing subset of features**.\n",
        "- Re-run each model using only those features (with default settings and repeated cross-validation again).\n",
        "- Report the **mean and standard deviation of CV MAE Scores**.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAu12j18d-M_"
      },
      "outputs": [],
      "source": [
        "# Add as many cells as you need\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "sfs_lr = SequentialFeatureSelector(\n",
        "    lr_model,\n",
        "    direction=\"forward\",\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=repeated_cv,\n",
        "    n_jobs=-1\n",
        ")\n",
        "sfs_lr.fit(X_train_scaled, y_train)\n",
        "selected_lr_features = X.columns[sfs_lr.get_support()]\n",
        "print(\"Linear Regression - Selected Features:\")\n",
        "print(selected_lr_features.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset the training data\n",
        "X_lr = X_train_scaled[:, sfs_lr.get_support()]\n",
        "\n",
        "# Cross-validation scores\n",
        "lr_scores = -cross_val_score(lr_model, X_lr, y_train,\n",
        "                             scoring=\"neg_mean_absolute_error\", cv=repeated_cv)\n",
        "print(f\"Linear Regression - Mean MAE: {lr_scores.mean():.2f}, Std MAE: {lr_scores.std():.2f}\")"
      ],
      "metadata": {
        "id": "OPkwCDP4nHpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtgWUtaARX1i"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestRegressor(random_state=42)\n",
        "sfs_rf = SequentialFeatureSelector(\n",
        "    rf,\n",
        "    n_features_to_select=15,\n",
        "    direction=\"forward\",\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=repeated_cv,\n",
        "    n_jobs=1\n",
        ")\n",
        "sfs_rf.fit(X_train_scaled, y_train)\n",
        "selected_rf_features = X_train.columns[sfs_rf.get_support()]\n",
        "print(\"Random Forest - Selected Features:\")\n",
        "print(selected_rf_features.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_rf = X_train_scaled[:, sfs_rf.get_support()]\n",
        "\n",
        "rf_scores = -cross_val_score(rf, X_rf, y_train,\n",
        "                             scoring=\"neg_mean_absolute_error\", cv=repeated_cv)\n",
        "print(f\"Random Forest - Mean MAE: {rf_scores.mean():.2f}, Std MAE: {rf_scores.std():.2f}\")"
      ],
      "metadata": {
        "id": "uNC4_CtVnRDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3thP0-majrd"
      },
      "outputs": [],
      "source": [
        "gb = GradientBoostingRegressor(random_state=42)\n",
        "sfs_gb = SequentialFeatureSelector(\n",
        "    gb,\n",
        "    n_features_to_select=15,\n",
        "    direction=\"forward\",\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=repeated_cv,\n",
        "    n_jobs=-1\n",
        ")\n",
        "sfs_gb.fit(X_train_scaled, y_train)\n",
        "selected_gb_features = X_train.columns[sfs_gb.get_support()]\n",
        "print(\"Gradient Boosting - Selected Features:\")\n",
        "print(selected_gb_features.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_gb = X_train_scaled[:, sfs_gb.get_support()]\n",
        "\n",
        "gb_scores = -cross_val_score(gb, X_gb, y_train,\n",
        "                             scoring=\"neg_mean_absolute_error\", cv=repeated_cv)\n",
        "print(f\"Gradient Boosting - Mean MAE: {gb_scores.mean():.2f}, Std MAE: {gb_scores.std():.2f}\")"
      ],
      "metadata": {
        "id": "sscHanKBnVpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFglLkwxd-NA"
      },
      "source": [
        "### Part 3: Discussion [3 pts]\n",
        "\n",
        "Analyze the effect of feature selection on your models:\n",
        "\n",
        "- Did performance improve for any models after reducing the number of features?\n",
        "\n",
        "- Which features were consistently retained across models?\n",
        "\n",
        "- Were any of your newly engineered features selected as important?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the linear regression model we were able to select the best features to run. Also, we are able to see that after applying feature selection algorithms the feature selected model performs slighly better on average. The feature selected model has a lower Mean MAE by almost 4,000 and a lower standard deviation MAE by almost 1,200."
      ],
      "metadata": {
        "id": "o4IYrmurmE7z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-BHxR3wd-NA"
      },
      "source": [
        "### Part 4: Fine-Tuning Your Three Models [6 pts]\n",
        "\n",
        "In this final phase of Milestone 2, you’ll select and refine your **three most promising models and their corresponding data pipelines** based on everything you've done so far, and pick a winner!\n",
        "\n",
        "1. For each of your three models:\n",
        "    - Choose your best engineered features and best selection of features as determined above.\n",
        "   - Perform hyperparameter tuning using `sweep_parameters`, `GridSearchCV`, `RandomizedSearchCV`, `Optuna`, etc. as you have practiced in previous homeworks.\n",
        "3. Decide on the best hyperparameters for each model, and for each run with repeated CV and record their final results:\n",
        "    - Report the **mean and standard deviation of CV MAE Score**.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIDnAFNLd-NA"
      },
      "outputs": [],
      "source": [
        "# Add as many cells as you need\n",
        "### Part 4.1 Choose your best engineered features and best selection of features as determined above. ###\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, RepeatedKFold, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Load & preprocess data\n",
        "df = pd.read_csv(\"zillow_cleaned.csv\")\n",
        "df[\"value_per_sqft\"] = df[\"taxvaluedollarcnt\"] / df[\"calculatedfinishedsquarefeet\"]\n",
        "df[\"bath_bed_ratio\"] = df[\"bathroomcnt\"] / (df[\"bedroomcnt\"] + 1)\n",
        "features = [\"calculatedfinishedsquarefeet\",\"bedroomcnt\",\"bathroomcnt\",\"yearbuilt\",\"lotsizesquarefeet\",\"value_per_sqft\",\"bath_bed_ratio\"]\n",
        "X = df[features]\n",
        "y = np.log1p(df[\"taxvaluedollarcnt\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models and param grids\n",
        "models = {\n",
        "    \"RandomForest\": (RandomForestRegressor(random_state=42), {\n",
        "        \"n_estimators\": [100, 200], \"max_depth\": [10, 20, None],\n",
        "        \"min_samples_split\": [2, 5], \"min_samples_leaf\": [1, 2]\n",
        "    }),\n",
        "    \"GradientBoosting\": (GradientBoostingRegressor(random_state=42), {\n",
        "        \"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "        \"max_depth\": [3, 5], \"subsample\": [0.8, 1.0]\n",
        "    }),\n",
        "    \"XGBoost\": (XGBRegressor(random_state=42, objective=\"reg:squarederror\"), {\n",
        "        \"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "        \"max_depth\": [3, 5], \"subsample\": [0.8, 1.0], \"colsample_bytree\": [0.8, 1.0]\n",
        "    }),\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, (model, params) in models.items():\n",
        "    pipeline = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "    param_dist = {f\"model__{k}\": v for k, v in params.items()}\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "        pipeline, param_distributions=param_dist, n_iter=10,\n",
        "        scoring=\"neg_mean_absolute_error\", cv=3,\n",
        "        random_state=42, n_jobs=1, verbose=0\n",
        "    )\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    best_model = search.best_estimator_\n",
        "\n",
        "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
        "    mae_scores = cross_val_score(\n",
        "        best_model, X, y,\n",
        "        scoring=\"neg_mean_absolute_error\",\n",
        "        cv=cv, n_jobs=1\n",
        "    )\n",
        "    mae_scores = -mae_scores\n",
        "\n",
        "    results[name] = {\n",
        "        \"best_params\": search.best_params_,\n",
        "        \"mean_mae\": mae_scores.mean(),\n",
        "        \"std_mae\": mae_scores.std()\n",
        "    }\n",
        "\n",
        "# Example: print results summary\n",
        "for model_name, res in results.items():\n",
        "    print(f\"{model_name}:\")\n",
        "    print(f\" Best Params: {res['best_params']}\")\n",
        "    print(f\" CV MAE: {res['mean_mae']:.4f} ± {res['std_mae']:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhmFk_D7eArc"
      },
      "outputs": [],
      "source": [
        "### 4.2 ####\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, RepeatedKFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load cleaned dataset\n",
        "df = pd.read_csv(\"zillow_cleaned.csv\")\n",
        "target = \"taxvaluedollarcnt\"\n",
        "\n",
        "# Create engineered features if missing\n",
        "if \"value_per_sqft\" not in df.columns:\n",
        "    df[\"value_per_sqft\"] = df[\"taxvaluedollarcnt\"] / df[\"calculatedfinishedsquarefeet\"]\n",
        "\n",
        "if \"bath_bed_ratio\" not in df.columns:\n",
        "    df[\"bath_bed_ratio\"] = df[\"bathroomcnt\"] / (df[\"bedroomcnt\"] + 1)\n",
        "\n",
        "# Selected features\n",
        "features = [\n",
        "    \"calculatedfinishedsquarefeet\",\n",
        "    \"bedroomcnt\",\n",
        "    \"bathroomcnt\",\n",
        "    \"yearbuilt\",\n",
        "    \"lotsizesquarefeet\",\n",
        "    \"value_per_sqft\",\n",
        "    \"bath_bed_ratio\"\n",
        "]\n",
        "\n",
        "X = df[features]\n",
        "y = np.log1p(df[target])\n",
        "\n",
        "# Train-test split for hyperparameter tuning\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define pipelines\n",
        "pipelines = {\n",
        "    \"RandomForest\": Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"model\", RandomForestRegressor(random_state=42)),\n",
        "    ]),\n",
        "    \"GradientBoosting\": Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"model\", GradientBoostingRegressor(random_state=42)),\n",
        "    ]),\n",
        "    \"XGBoost\": Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"model\", XGBRegressor(random_state=42, objective=\"reg:squarederror\")),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Hyperparameter grids\n",
        "param_grids = {\n",
        "    \"RandomForest\": {\n",
        "        \"model__n_estimators\": [100, 200],\n",
        "        \"model__max_depth\": [10, 20, None],\n",
        "        \"model__min_samples_split\": [2, 5],\n",
        "        \"model__min_samples_leaf\": [1, 2],\n",
        "    },\n",
        "    \"GradientBoosting\": {\n",
        "        \"model__n_estimators\": [100, 200],\n",
        "        \"model__learning_rate\": [0.01, 0.1, 0.2],\n",
        "        \"model__max_depth\": [3, 5],\n",
        "        \"model__subsample\": [0.8, 1.0],\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"model__n_estimators\": [100, 200],\n",
        "        \"model__learning_rate\": [0.01, 0.1, 0.2],\n",
        "        \"model__max_depth\": [3, 5],\n",
        "        \"model__subsample\": [0.8, 1.0],\n",
        "        \"model__colsample_bytree\": [0.8, 1.0],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Hyperparameter tuning\n",
        "def tune_model(name, pipeline, param_grid, X_train, y_train):\n",
        "    print(f\"\\nTuning {name}...\")\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=pipeline,\n",
        "        param_distributions=param_grid,\n",
        "        n_iter=10,\n",
        "        scoring=\"neg_mean_absolute_error\",\n",
        "        cv=3,\n",
        "        verbose=0,\n",
        "        random_state=42,\n",
        "        n_jobs=1\n",
        "    )\n",
        "    search.fit(X_train, y_train)\n",
        "    return search.best_estimator_, search.best_params_\n",
        "\n",
        "# Evaluate with Repeated CV\n",
        "def evaluate_model(model, X, y):\n",
        "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
        "    mae_scores = cross_val_score(\n",
        "        model, X, y, scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=1\n",
        "    )\n",
        "    mae_scores = -mae_scores\n",
        "    return mae_scores.mean(), mae_scores.std()\n",
        "\n",
        "# Run all models and collect results\n",
        "results = {}\n",
        "for name in pipelines:\n",
        "    best_model, best_params = tune_model(name, pipelines[name], param_grids[name], X_train, y_train)\n",
        "    mean_mae, std_mae = evaluate_model(best_model, X, y)\n",
        "    results[name] = {\n",
        "        \"best_params\": best_params,\n",
        "        \"mean_MAE\": mean_mae,\n",
        "        \"std_MAE\": std_mae\n",
        "    }\n",
        "\n",
        "# Print formatted report\n",
        "print(\"\\n=== Final CV Results (MAE) ===\")\n",
        "for model, vals in results.items():\n",
        "    print(f\"\\nModel: {model}\")\n",
        "    print(\" Best Hyperparameters:\", vals[\"best_params\"])\n",
        "    print(f\" Repeated CV MAE: {vals['mean_MAE']:.4f} ± {vals['std_MAE']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMZm-quCd-NA"
      },
      "source": [
        "### Part 4: Discussion [3 pts]\n",
        "\n",
        "Reflect on your tuning process and final results:\n",
        "\n",
        "- What was your tuning strategy for each model? Why did you choose those hyperparameters?\n",
        "- Did you find that certain types of preprocessing or feature engineering worked better with specific models?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DATjIR_rd-NA"
      },
      "source": [
        "After completing the tuning process and evaluating each model with repeated cross‑validation, we found that the boosting methods, particularly XGBoost, responded best to both hyperparameter optimization and our engineered features. Random Forest was more stable and required less tuning effort, but it did not achieve the same level of accuracy. Gradient Boosting improved with careful adjustments to the learning rate and number of estimators, but XGBoost’s additional flexibility with feature and sample subsampling gave it a slight edge. Based on these results, we selected XGBoost as our final model, as it consistently achieved the lowest MAE and demonstrated strong generalization across folds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_-X4vqFd-NA"
      },
      "source": [
        "### Part 5: Final Model and Design Reassessment [6 pts]\n",
        "\n",
        "In this part, you will finalize your best-performing model.  You’ll also consolidate and present the key code used to run your model on the preprocessed dataset.\n",
        "**Requirements:**\n",
        "\n",
        "- Decide one your final model among the three contestants.\n",
        "\n",
        "- Below, include all code necessary to **run your final model** on the processed dataset, reporting\n",
        "\n",
        "    - Mean and standard deviation of CV MAE Score.\n",
        "    \n",
        "    - Test score on held-out test set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0bz7xmmd-NA"
      },
      "outputs": [],
      "source": [
        "# Add as many cells as you need\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zKbs9Jad-NB"
      },
      "source": [
        "### Part 5: Discussion [8 pts]\n",
        "\n",
        "In this final step, your goal is to synthesize your entire modeling process and assess how your earlier decisions influenced the outcome. Please address the following:\n",
        "\n",
        "1. Model Selection:\n",
        "- Clearly state which model you selected as your final model and why.\n",
        "\n",
        "- What metrics or observations led you to this decision?\n",
        "\n",
        "- Were there trade-offs (e.g., interpretability vs. performance) that influenced your choice?\n",
        "\n",
        "2. Revisiting an Early Decision\n",
        "\n",
        "- Identify one specific preprocessing or feature engineering decision from Milestone 1 (e.g., how you handled missing values, how you scaled or encoded a variable, or whether you created interaction or polynomial terms).\n",
        "\n",
        "- Explain the rationale for that decision at the time: What were you hoping it would achieve?\n",
        "\n",
        "- Now that you've seen the full modeling pipeline and final results, reflect on whether this step helped or hindered performance. Did you keep it, modify it, or remove it?\n",
        "\n",
        "- Justify your final decision with evidence—such as validation scores, visualizations, or model diagnostics.\n",
        "\n",
        "3. Lessons Learned\n",
        "\n",
        "- What insights did you gain about your dataset or your modeling process through this end-to-end workflow?\n",
        "\n",
        "- If you had more time or data, what would you explore next?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_herYztd-NB"
      },
      "source": [
        "> Your text here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}